{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8470c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Sequence, TypedDict, Union\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "import sqlglot\n",
    "from sqlglot import parse_one\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "# from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "# from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# from langchain_core.documents import Document #as LCDocument\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ddfe848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "OPENAI_API_KEY=os.getenv('AZURE_OPENAI_API_KEY_US')\n",
    "OPENAI_API_KEY_E=os.getenv('AZURE_OPENAI_API_KEY_US2') \n",
    "\n",
    "# os.environ['OPENAI_API_TYPE'] = 'azure'\n",
    "os.environ['OPENAI_API_VERSION'] = '2024-08-01-preview'\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://azure-chat-try-2.openai.azure.com/'\n",
    "os.environ['AZURE_OPENAI_DEPLOYMENT'] = 'chat-endpoint-us-gpt4o'\n",
    "\n",
    "os.environ['OPENAI_API_VERSION_E'] = '2024-12-01-preview'\n",
    "os.environ['AZURE_OPENAI_ENDPOINT_E'] = 'https://agents-4on.openai.azure.com/'\n",
    "os.environ['AZURE_OPENAI_EMBEDDING_DEPLOYMENT_E'] = \"text-embedding-3-large-eus2\"\n",
    "\n",
    "# LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "# os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "# os.environ['LANGCHAIN_PROJECT'] = \"rag-sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7e9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    api_key = OPENAI_API_KEY,  \n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    ")\n",
    "\n",
    "emb_model = AzureOpenAIEmbeddings(\n",
    "    api_key=OPENAI_API_KEY_E,\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT_E'),  \n",
    "    api_version=os.getenv('OPENAI_API_VERSION_E'),\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT_E')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f48e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "\n",
    "# from langchain_community.utilities import SQLDatabase\n",
    "# db = SQLDatabase.from_uri(\"sqlite:///./database/credit-risk.db\", sample_rows_in_table_info=2)\n",
    "# print(db.dialect)\n",
    "# print(db.get_usable_table_names())\n",
    "\n",
    "engine = create_engine(\"sqlite:///./database/credit-risk.db\", future=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7202d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"risk_db_tables\",\n",
    "    embedding_function=emb_model,\n",
    "    persist_directory=\"./vector_db\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# # Prompt\n",
    "# template = \"\"\"Answer the question based only on the following context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# rag_chain = (\n",
    "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "\n",
    "# res = rag_chain.invoke(\"How can I get the total undrawn exposure per economic sector?\")\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a382a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a412d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a26c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sql tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348365de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sql tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4536b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write sql prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fdf1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write final answer prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2f52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever node\n",
    "\n",
    "# def start_node(state: ChatState) -> ChatState:\n",
    "#     \"\"\"\n",
    "#     Entry node. Expects the latest user message to be present in state.messages.\n",
    "#     Calls db_retriever tool by returning its Command (tools may be called directly).\n",
    "#     \"\"\"\n",
    "#     # The latest HumanMessage content\n",
    "#     msgs = state.get(\"messages\", [])\n",
    "#     last_msg = msgs[-1] if msgs else HumanMessage(content=\"\")\n",
    "#     question = last_msg.content if hasattr(last_msg, \"content\") else str(last_msg)\n",
    "\n",
    "#     db_retriever.invoke({\"question\": question})\n",
    "\n",
    "#     return state\n",
    "\n",
    "# OR\n",
    "\n",
    "#     return db_retriever.invoke({\"question\": question})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52116539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sql node\n",
    "\n",
    "# llm.invoke with prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9a9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql run node\n",
    "\n",
    "# res = run_sql.invoke({\"sql\": sql})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baec17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final answer node\n",
    "\n",
    "# llm.invoke with prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d5066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21892c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc9bc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(MessagesState):\n",
    "    retrieved_docs: List[Dict[str, Any]]\n",
    "    sql_query: str\n",
    "    query_results: List[Dict[str, Any]]\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "# class ChatState(TypedDict):\n",
    "#     # MessagesState requirements\n",
    "#     messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "#     retrieved_docs: List[Dict[str, Any]]\n",
    "#     sql_query: str\n",
    "#     query_results: List[Dict[str, Any]]\n",
    "#     final_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dddd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def db_retriever(question: str, limit = 4, runtime=None) -> Command:\n",
    "    \"\"\"\n",
    "    Semantic retrieval from Chroma. Returns Command that:\n",
    "      - appends a ToolMessage describing the retrieval to `messages` (MessagesState reducer will append),\n",
    "      - updates `retrieved_docs`,\n",
    "      - routes to \"sql_writer\".\n",
    "    \"\"\"\n",
    "    results = vector_store.similarity_search(question, k=limit)\n",
    "    docs_serial = [\n",
    "        {\"table\": d.metadata.get(\"table\"), \"source_file\": d.metadata.get(\"source_file\"), \"snippet\": d.page_content[:800]}\n",
    "        for d in results\n",
    "    ]\n",
    "\n",
    "    # Stream small progress to caller UI if available\n",
    "    if runtime and getattr(runtime, \"stream_writer\", None):\n",
    "        runtime.stream_writer(f\"Retrieved {len(docs_serial)} docs from the schema store.\")\n",
    "\n",
    "    # Append a ToolMessage (messages reducer will append, not overwrite)\n",
    "    tool_msg = ToolMessage(content=f\"Retriever: found {len(docs_serial)} docs relevant to the question.\")\n",
    "\n",
    "    # Command: update messages and retrieved_docs, then goto sql_writer\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [tool_msg],         # MessagesState reducer handles appending/deserializing\n",
    "            \"retrieved_docs\": docs_serial,  # Regular state key update (replaced/merged)\n",
    "        },\n",
    "        goto=\"sql_writer\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e78f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sql_writer(question: str, retrieved_docs: List[Dict[str, Any]], runtime: ToolRuntime | None = None) -> Command:\n",
    "    \"\"\"\n",
    "    Produce a SQL query based on the question & retrieved schema snippets.\n",
    "    Returns a Command that updates `sql_query`, appends a ToolMessage with the SQL,\n",
    "    and routes to 'execute_sql'.\n",
    "    \"\"\"\n",
    "    docs_text = \"\\n\\n\".join([f\"Table: {d.get('table')}\\nSnippet: {d.get('snippet')}\" for d in retrieved_docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Produce a single SQL statement that answers the user's question. Return only the SQL.\n",
    "        User question:\n",
    "        {question}\n",
    "\n",
    "        Relevant schema snippets:\n",
    "        {docs_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    # sql = llm(prompt).strip()\n",
    "    response = llm.invoke(prompt)\n",
    "    sql = response.content.strip()\n",
    "\n",
    "    if runtime and getattr(runtime, \"stream_writer\", None):\n",
    "        runtime.stream_writer(\"Generated SQL query.\")\n",
    "\n",
    "    tool_msg = ToolMessage(content=f\"SQL generated: {sql}\")\n",
    "\n",
    "    return Command(\n",
    "        update={\"sql_query\": sql, \"messages\": [tool_msg]},\n",
    "        goto=\"execute_sql\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_node(state: ChatState): # or node_retriever()\n",
    "    \"\"\"\n",
    "    Entry node. Expects the latest user message to be present in state.messages.\n",
    "    Calls db_retriever tool by returning its Command (tools may be called directly).\n",
    "    \"\"\"\n",
    "    # The latest HumanMessage content\n",
    "    msgs = state.get(\"messages\", [])\n",
    "    last_msg = msgs[-1] if msgs else HumanMessage(content=\"\")\n",
    "    question = last_msg.content if hasattr(last_msg, \"content\") else str(last_msg)\n",
    "\n",
    "    # return a Command or call a tool, e.g. call retriever tool (tool returns Command)\n",
    "    return db_retriever(question)\n",
    "    # return db_retriever({\"question\": question})\n",
    "\n",
    "\n",
    "# def start_node(state: ChatState) -> ChatState:\n",
    "#     \"\"\"\n",
    "#     Entry node. Expects the latest user message to be present in state.messages.\n",
    "#     Calls db_retriever tool by returning its Command (tools may be called directly).\n",
    "#     \"\"\"\n",
    "#     # The latest HumanMessage content\n",
    "#     msgs = state.get(\"messages\", [])\n",
    "#     last_msg = msgs[-1] if msgs else HumanMessage(content=\"\")\n",
    "#     question = last_msg.content if hasattr(last_msg, \"content\") else str(last_msg)\n",
    "\n",
    "#     db_retriever.invoke({\"question\": question})\n",
    "\n",
    "#     return state\n",
    "\n",
    "# OR\n",
    "\n",
    "#     return db_retriever.invoke({\"question\": question})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4acb16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "def execute_sql_node(state: ChatState):\n",
    "    \"\"\"\n",
    "    Run the SQL stored in state['sql_query'] against a demo sqlite DB,\n",
    "    update `query_results` and append a ToolMessage with a short summary,\n",
    "    then route to 'finalize'.\n",
    "    \"\"\"\n",
    "    sql = state.get(\"sql_query\", \"\")\n",
    "    if not sql:\n",
    "        # nothing to run â†’ still go to finalize\n",
    "        return Command(update={\"query_results\": []}, goto=\"finalize\")\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # Use text() to wrap raw SQL safely in SQLAlchemy\n",
    "            result = conn.execute(text(sql))\n",
    "            # If SELECT, fetch results\n",
    "            rows = result.fetchall()\n",
    "            # Convert Row objects to dictionaries (Row._mapping is stable)\n",
    "            results = [dict(row._mapping) for row in rows]\n",
    "            summary = f\"Executed SQL, returned {len(results)} rows.\"\n",
    "    except SQLAlchemyError as e:\n",
    "        results = [{\"error\": str(e)}]\n",
    "        summary = f\"SQL execution error: {str(e)}\"\n",
    "\n",
    "    # Append a small ToolMessage so the messages channel contains the execution note\n",
    "    tool_msg = ToolMessage(content=summary)\n",
    "\n",
    "    # Update structured results and messages; route to finalize\n",
    "    return Command(update={\"query_results\": results, \"messages\": [tool_msg]}, goto=\"finalize\")\n",
    "\n",
    "\n",
    "    # results = db.run_no_throw(sql)\n",
    "\n",
    "    # # Demo: in-memory SQLite with tiny sample data (replace in prod)\n",
    "    # conn = sqlite3.connect(\":memory:\")\n",
    "    # cur = conn.cursor()\n",
    "    # cur.executescript(\n",
    "    #     \"\"\"\n",
    "    #     CREATE TABLE customers(ref_date TEXT, partner_id TEXT, pd REAL, country TEXT);\n",
    "    #     CREATE TABLE collaterals(ref_date TEXT, coll_id TEXT, mkt_value REAL);\n",
    "    #     INSERT INTO customers VALUES ('2024-08-31','C001',0.02,'AT');\n",
    "    #     INSERT INTO customers VALUES ('2024-08-31','C002',0.15,'NL');\n",
    "    #     INSERT INTO collaterals VALUES ('2024-08-31','L001',100000.0);\n",
    "    #     \"\"\"\n",
    "    # )\n",
    "    # conn.commit()\n",
    "\n",
    "    # try:\n",
    "    #     cur.execute(sql)\n",
    "    #     cols = [d[0] for d in cur.description] if cur.description else []\n",
    "    #     rows = cur.fetchall()\n",
    "    #     results = [dict(zip(cols, row)) for row in rows)]\n",
    "    #     summary = f\"SQL executed successfully: {len(results)} rows.\"\n",
    "    # except Exception as e:\n",
    "    #     results = [{\"error\": str(e)}]\n",
    "    #     summary = f\"SQL execution failed: {str(e)}\"\n",
    "    # finally:\n",
    "    #     conn.close()\n",
    "\n",
    "    # # Append a ToolMessage summarizing execution and update results\n",
    "    # tool_msg = ToolMessage(content=summary)\n",
    "    # return Command(update={\"query_results\": results, \"messages\": [tool_msg]}, goto=\"finalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03445c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_node(state):\n",
    "    # read query_results as structured state\n",
    "    results = state.get(\"query_results\", [])\n",
    "    # append an AI reply into messages via Command update (MessagesState reducer will append)\n",
    "    reply = AIMessage(content=\"Here are the results...\")\n",
    "    return Command(update={\"final_answer\": \"Answer text\", \"messages\": [reply]}, goto=\"__end__\")\n",
    "\n",
    "# def finalize_node(state: ChatState):\n",
    "#     \"\"\"\n",
    "#     Summarize the query_results for the user using the LLM.\n",
    "#     Append an AIMessage and set `final_answer`.\n",
    "#     \"\"\"\n",
    "#     last_user = None\n",
    "#     # Find latest HumanMessage (safely)\n",
    "#     for m in reversed(state.messages):\n",
    "#         if isinstance(m, HumanMessage):\n",
    "#             last_user = m.content\n",
    "#             break\n",
    "#     question = last_user or \"the user's question\"\n",
    "\n",
    "#     prompt = f\"\"\"\n",
    "#         User asked: {question}\n",
    "\n",
    "#         SQL results (JSON): {json.dumps(state.get('query_results', []), indent=2)}\n",
    "\n",
    "#         Write a short, clear answer to the user that explains the results.\n",
    "#     \"\"\"\n",
    "#     answer_text = llm.invoke(prompt)\n",
    "\n",
    "#     ai_msg = AIMessage(content=answer_text)\n",
    "#     return Command(update={\"final_answer\": answer_text, \"messages\": [ai_msg]}, goto=END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69a7b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"start\", start_node)\n",
    "# We add a node wrapper for sql_writer so the graph knows it exists as a node;\n",
    "# the sql_writer itself is implemented as a tool returning a Command.\n",
    "graph.add_node(\"sql_writer\", lambda state: sql_writer(state.messages[-1].content, state.get(\"retrieved_docs\", [])), ends=[\"execute_sql\"])\n",
    "graph.add_node(\"execute_sql\", execute_sql_node, ends=[\"finalize\"])\n",
    "graph.add_node(\"finalize\", finalize_node)\n",
    "graph.add_edge(START, \"start\")\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0edc707",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'StructuredTool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Initialize with a HumanMessage in messages (MessagesState will keep this channel)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the market value for collateral L001 at the latest date?\u001b[39m\u001b[38;5;124m\"\u001b[39m)]}\n\u001b[0;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph result state keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieved_docs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieved_docs\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/langgraph/pregel/main.py:3050\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3047\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3048\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3050\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3059\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3060\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3062\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3064\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/langgraph/pregel/main.py:2633\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2632\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2633\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   2640\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmpty\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2643\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 656\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m, in \u001b[0;36mstart_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      9\u001b[0m question \u001b[38;5;241m=\u001b[39m last_msg\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_msg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(last_msg)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# return a Command or call a tool, e.g. call retriever tool (tool returns Command)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdb_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'StructuredTool' object is not callable",
      "\u001b[0mDuring task with name 'start' and id 'a437d3d7-0481-f0b1-6876-fee045ade79f'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize with a HumanMessage in messages (MessagesState will keep this channel)\n",
    "    initial_state = {\"messages\": [HumanMessage(content=\"What is the market value for collateral L001 at the latest date?\")]}\n",
    "\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(\"Graph result state keys:\")\n",
    "    print(\"retrieved_docs:\", result.get(\"retrieved_docs\"))\n",
    "    print(\"sql_query:\", result.get(\"sql_query\"))\n",
    "    print(\"query_results:\", result.get(\"query_results\"))\n",
    "    print(\"final_answer:\", result.get(\"final_answer\"))\n",
    "\n",
    "    # # The `messages` channel contains the conversation history (user, tool annotations, and final AI response)\n",
    "    # print(\"\\nConversation messages (last 5):\")\n",
    "    # for m in result[\"messages\"][-5:]:\n",
    "    #     print(type(m).__name__, \":\", m.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ecc662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".agents-ud (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
