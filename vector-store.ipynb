{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca52003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from typing import Dict, Any, List\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY_E=os.getenv('AZURE_OPENAI_API_KEY_US2')\n",
    "os.environ['OPENAI_API_VERSION_E'] = '2024-12-01-preview'\n",
    "os.environ['AZURE_OPENAI_ENDPOINT_E'] = 'https://agents-4on.openai.azure.com/'\n",
    "os.environ['AZURE_OPENAI_EMBEDDING_DEPLOYMENT_E'] = \"text-embedding-3-large-eus2\"\n",
    "\n",
    "emb_model = AzureOpenAIEmbeddings(\n",
    "    api_key=OPENAI_API_KEY_E,\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT_E'),  \n",
    "    api_version=os.getenv('OPENAI_API_VERSION_E'),\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT_E')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a single table JSON into readable text\n",
    "def table_json_to_text(table_json: Dict[str, Any]) -> str:\n",
    "    lines = []\n",
    "    lines.append(f\"Table: {table_json.get('table', '')}\")\n",
    "    if desc := table_json.get(\"description\"):\n",
    "        lines.append(f\"Description: {desc}\")\n",
    "    lines.append(\"\")  # blank line\n",
    "\n",
    "    lines.append(\"Columns:\")\n",
    "    for col in table_json.get(\"columns\", []):\n",
    "        name = col.get(\"name\")\n",
    "        ctype = col.get(\"type\")\n",
    "        nullable = col.get(\"nullable\")\n",
    "        desc = col.get(\"description\", \"\")\n",
    "        allowed = col.get(\"allowed_values\")\n",
    "        lines.append(f\"- {name} ({ctype}) - nullable={nullable}\")\n",
    "        if desc:\n",
    "            lines.append(f\"  Description: {desc}\")\n",
    "        if allowed:\n",
    "            allowed_items = \", \".join([f\"{k}: {v}\" for k, v in allowed.items()])\n",
    "            lines.append(f\"  Allowed values: {allowed_items}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    if constraints := table_json.get(\"constraints\"):\n",
    "        lines.append(\"Constraints:\")\n",
    "        for k, v in constraints.items():\n",
    "            cols = v.get(\"columns\")\n",
    "            desc = v.get(\"description\")\n",
    "            lines.append(f\"- {k}: columns={cols} - {desc}\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    if relationships := table_json.get(\"relationships\"):\n",
    "        lines.append(\"Relationships:\")\n",
    "        for rel in relationships:\n",
    "            related = rel.get(\"related_table\")\n",
    "            join = rel.get(\"join_type\")\n",
    "            card = rel.get(\"cardinality\")\n",
    "            notes = rel.get(\"notes\")\n",
    "            lines.append(f\"- Related table: {related} ({join}) -- {card}\")\n",
    "            if notes:\n",
    "                lines.append(f\"  Notes: {notes}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef048f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all .json files from a directory and return Document objects\n",
    "def load_table_documents_from_dir(dir_path: str) -> List[Document]:\n",
    "    docs: List[Document] = []\n",
    "    pattern = os.path.join(dir_path, \"*.json\")\n",
    "    files = sorted(glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .json files found in directory: {dir_path}\")\n",
    "    for fp in files:\n",
    "        with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "            table_json = json.load(f)\n",
    "        text = table_json_to_text(table_json)\n",
    "        metadata = {\n",
    "            \"table\": table_json.get(\"table\"),\n",
    "            \"source_file\": os.path.basename(fp),\n",
    "        }\n",
    "        docs.append(Document(page_content=text, metadata=metadata))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing into Chroma (embeds + stores)\n",
    "def index_dir_to_chroma(\n",
    "    dir_path: str,\n",
    "    collection_name: str = \"db_tables_collection\",\n",
    "    persist_dir: str = \"./chroma_db\",\n",
    "    openai_model: str = \"text-embedding-3-large\",\n",
    "):\n",
    "    # Initialize embeddings (requires OPENAI_API_KEY)\n",
    "    # embeddings = OpenAIEmbeddings(model=openai_model)\n",
    "\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        api_key=OPENAI_API_KEY_E,\n",
    "        azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT_E'),  \n",
    "        api_version=os.getenv('OPENAI_API_VERSION_E'),\n",
    "        azure_deployment=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT_E')    \n",
    "    )\n",
    "    \n",
    "    # embeddings = emb_model\n",
    "   \n",
    "    # Initialize Chroma\n",
    "    vector_store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=persist_dir,\n",
    "    )\n",
    "\n",
    "    # Load Docs from directory\n",
    "    docs = load_table_documents_from_dir(dir_path)\n",
    "\n",
    "    # Add documents (Chroma will compute embeddings)\n",
    "    vector_store.add_documents(docs)\n",
    "\n",
    "    # persist (if available)\n",
    "    try:\n",
    "        vector_store.persist()\n",
    "    except Exception:\n",
    "        # persist may be optional depending on langchain-chroma version\n",
    "        pass\n",
    "\n",
    "    print(f\"Indexed {len(docs)} docs from '{dir_path}' into collection '{collection_name}'\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a642885",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_info_dir = \"database\"\n",
    "\n",
    "chroma_store = index_dir_to_chroma(\n",
    "    dir_path=db_info_dir,\n",
    "    collection_name=\"bank_schema_tables\",\n",
    "    persist_dir=\"./chroma_db\",\n",
    "    openai_model=\"text-embedding-3-large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval examples: similarity search + metadata filtered search\n",
    "def retrieval_examples(vector_store: Chroma, queries: List[str], top_k: int = 3):\n",
    "    for q in queries:\n",
    "        print(\"\\nQuery:\", q)\n",
    "        results = vector_store.similarity_search(q, k=top_k)\n",
    "        for i, doc in enumerate(results, start=1):\n",
    "            print(f\"{i}. table={doc.metadata.get('table')} file={doc.metadata.get('source_file')}\")\n",
    "            print(\"   snippet:\", doc.page_content[:900].replace(\"\\n\", \" \").strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example main\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory where your JSON files live\n",
    "    db_info_dir = \"database\"  # <-- put collaterals.json, customers.json, transactions.json, sectors.json here\n",
    "\n",
    "    # 1) Index\n",
    "    chroma_store = index_dir_to_chroma(\n",
    "        dir_path=db_info_dir,\n",
    "        collection_name=\"bank_schema_tables\",\n",
    "        persist_dir=\"./chroma_db\",\n",
    "        openai_model=\"text-embedding-3-small\",\n",
    "    )\n",
    "\n",
    "    # 2) Retrieval\n",
    "    queries = [\n",
    "        \"Which column stores market value of collateral?\",\n",
    "        \"Where is customer PD stored?\",\n",
    "        \"How do transactions reference customers?\",\n",
    "    ]\n",
    "    retrieval_examples(chroma_store, queries, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41061653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e00f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Convert a single table JSON into readable text\n",
    "def table_json_to_text(table_json: Dict[str, Any]) -> str:\n",
    "    lines = []\n",
    "    lines.append(f\"Table: {table_json.get('table', '')}\")\n",
    "    if desc := table_json.get(\"description\"):\n",
    "        lines.append(f\"Description: {desc}\")\n",
    "    lines.append(\"\")  # blank line\n",
    "\n",
    "    lines.append(\"Columns:\")\n",
    "    for col in table_json.get(\"columns\", []):\n",
    "        name = col.get(\"name\")\n",
    "        ctype = col.get(\"type\")\n",
    "        nullable = col.get(\"nullable\")\n",
    "        desc = col.get(\"description\", \"\")\n",
    "        allowed = col.get(\"allowed_values\")\n",
    "        lines.append(f\"- {name} ({ctype}) - nullable={nullable}\")\n",
    "        if desc:\n",
    "            lines.append(f\"  Description: {desc}\")\n",
    "        if allowed:\n",
    "            allowed_items = \", \".join([f\"{k}: {v}\" for k, v in allowed.items()])\n",
    "            lines.append(f\"  Allowed values: {allowed_items}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    if constraints := table_json.get(\"constraints\"):\n",
    "        lines.append(\"Constraints:\")\n",
    "        for k, v in constraints.items():\n",
    "            cols = v.get(\"columns\")\n",
    "            desc = v.get(\"description\")\n",
    "            lines.append(f\"- {k}: columns={cols} - {desc}\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    if relationships := table_json.get(\"relationships\"):\n",
    "        lines.append(\"Relationships:\")\n",
    "        for rel in relationships:\n",
    "            related = rel.get(\"related_table\")\n",
    "            join = rel.get(\"join_type\")\n",
    "            card = rel.get(\"cardinality\")\n",
    "            notes = rel.get(\"notes\")\n",
    "            lines.append(f\"- Related table: {related} ({join}) -- {card}\")\n",
    "            if notes:\n",
    "                lines.append(f\"  Notes: {notes}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Load all .json files from a directory and return Document objects\n",
    "def load_table_documents_from_dir(dir_path: str) -> List[Document]:\n",
    "    docs: List[Document] = []\n",
    "    pattern = os.path.join(dir_path, \"*.json\")\n",
    "    files = sorted(glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .json files found in directory: {dir_path}\")\n",
    "    for fp in files:\n",
    "        with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "            table_json = json.load(f)\n",
    "        text = table_json_to_text(table_json)\n",
    "        metadata = {\n",
    "            \"table\": table_json.get(\"table\"),\n",
    "            \"source_file\": os.path.basename(fp),\n",
    "        }\n",
    "        docs.append(Document(page_content=text, metadata=metadata))\n",
    "    return docs\n",
    "\n",
    "# Indexing into Chroma (embeds + stores)\n",
    "def index_dir_to_chroma(\n",
    "    dir_path: str,\n",
    "    collection_name: str = \"db_tables_collection\",\n",
    "    persist_dir: str = \"./chroma_db\",\n",
    "    openai_model: str = \"text-embedding-3-small\",\n",
    "):\n",
    "    # Initialize embeddings (requires OPENAI_API_KEY)\n",
    "    embeddings = OpenAIEmbeddings(model=openai_model)\n",
    "\n",
    "    # Initialize Chroma\n",
    "    vector_store = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=persist_dir,\n",
    "    )\n",
    "\n",
    "    # Load Docs from directory\n",
    "    docs = load_table_documents_from_dir(dir_path)\n",
    "\n",
    "    # Add documents (Chroma will compute embeddings)\n",
    "    vector_store.add_documents(docs)\n",
    "\n",
    "    # persist (if available)\n",
    "    try:\n",
    "        vector_store.persist()\n",
    "    except Exception:\n",
    "        # persist may be optional depending on langchain-chroma version\n",
    "        pass\n",
    "\n",
    "    print(f\"Indexed {len(docs)} docs from '{dir_path}' into collection '{collection_name}'\")\n",
    "    return vector_store\n",
    "\n",
    "# Retrieval examples: similarity search + metadata filtered search\n",
    "def retrieval_examples(vector_store: Chroma, queries: List[str], top_k: int = 3):\n",
    "    for q in queries:\n",
    "        print(\"\\nQuery:\", q)\n",
    "        results = vector_store.similarity_search(q, k=top_k)\n",
    "        for i, doc in enumerate(results, start=1):\n",
    "            print(f\"{i}. table={doc.metadata.get('table')} file={doc.metadata.get('source_file')}\")\n",
    "            print(\"   snippet:\", doc.page_content[:300].replace(\"\\n\", \" \").strip(), \"\\n\")\n",
    "\n",
    "    # Example: filter to a specific table\n",
    "    q = \"market value of collateral\"\n",
    "    print(\"\\nFiltered query (table=collaterals):\", q)\n",
    "    filtered = vector_store.similarity_search(q, k=3, filter={\"table\": \"collaterals\"})\n",
    "    for i, doc in enumerate(filtered, start=1):\n",
    "        print(f\"{i}. table={doc.metadata.get('table')} file={doc.metadata.get('source_file')}\")\n",
    "\n",
    "# Example main\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory where your JSON files live\n",
    "    db_info_dir = \"db_info\"  # <-- put collaterals.json, customers.json, transactions.json, sectors.json here\n",
    "\n",
    "    # 1) Index\n",
    "    chroma_store = index_dir_to_chroma(\n",
    "        dir_path=db_info_dir,\n",
    "        collection_name=\"bank_schema_tables\",\n",
    "        persist_dir=\"./chroma_db\",\n",
    "        openai_model=\"text-embedding-3-small\",\n",
    "    )\n",
    "\n",
    "    # 2) Retrieval\n",
    "    queries = [\n",
    "        \"Which column stores market value of collateral?\",\n",
    "        \"Where is customer PD stored?\",\n",
    "        \"How do transactions reference customers?\",\n",
    "    ]\n",
    "    retrieval_examples(chroma_store, queries, top_k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".agents-ud (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
