{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acbf6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import uuid\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ff878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY_E=os.getenv('AZURE_OPENAI_API_KEY_US2')\n",
    "os.environ['OPENAI_API_VERSION_E'] = '2024-12-01-preview'\n",
    "os.environ['AZURE_OPENAI_ENDPOINT_E'] = 'https://agents-4on.openai.azure.com/'\n",
    "os.environ['AZURE_OPENAI_EMBEDDING_DEPLOYMENT_E'] = \"text-embedding-3-large-eus2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57feb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"./database\"                  # Folder with .json files\n",
    "PERSIST_DIR = \"./database\"                # Chroma persistence path\n",
    "COLLECTION_NAME = \"json_embeddings\"       # Logical collection name\n",
    "RESET_COLLECTION = False                  # If True, clears existing data\n",
    "\n",
    "# Chunking (safe defaults for text-embedding-3-* models)\n",
    "TARGET_CHUNK_TOKENS = 800\n",
    "CHUNK_OVERLAP_TOKENS = 50\n",
    "\n",
    "\n",
    "# Optional: only embed some fields if your JSON has consistent schema\n",
    "ONLY_FIELDS: Optional[List[str]] = None\n",
    "# e.g.: ONLY_FIELDS = [\"title\", \"summary\", \"body\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354fb240",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=OPENAI_API_KEY_E,\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT_E'),  \n",
    "    api_version=os.getenv('OPENAI_API_VERSION_E'),\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT_E')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74feafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def flatten_json(obj: Any, prefix: str = \"\") -> List[str]:\n",
    "    \"\"\"Flatten any JSON to lines like 'path.to.key: value' for embedding.\"\"\"\n",
    "    lines: List[str] = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            new_prefix = f\"{prefix}.{k}\" if prefix else k\n",
    "            lines.extend(flatten_json(v, new_prefix))\n",
    "    elif isinstance(obj, list):\n",
    "        for i, v in enumerate(obj):\n",
    "            new_prefix = f\"{prefix}[{i}]\"\n",
    "            lines.extend(flatten_json(v, new_prefix))\n",
    "    else:\n",
    "        val = \"\" if obj is None else str(obj)\n",
    "        if prefix:\n",
    "            lines.append(f\"{prefix}: {val}\")\n",
    "        else:\n",
    "            lines.append(val)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def json_to_text(obj: Any, file_name: str) -> str:\n",
    "    \"\"\"Turn JSON into a readable text block, optionally selecting fields.\"\"\"\n",
    "    if ONLY_FIELDS and isinstance(obj, dict):\n",
    "        subset: Dict[str, Any] = {k: obj.get(k) for k in ONLY_FIELDS if k in obj}\n",
    "        lines = flatten_json(subset, \"\")\n",
    "    else:\n",
    "        lines = flatten_json(obj, \"\")\n",
    "    header = f\"Source: {file_name}\\n\"\n",
    "    return header + \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def load_json_files(input_dir: str) -> List[Document]:\n",
    "    \"\"\"Load .json files and convert to LangChain Documents (with chunking).\"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(input_dir, \"*.json\")))\n",
    "    if not paths:\n",
    "        print(f\"[Info] No .json files found under: {input_dir}\")\n",
    "        return []\n",
    "\n",
    "    splitter = TokenTextSplitter(\n",
    "        encoding_name=\"cl100k_base\",\n",
    "        chunk_size=TARGET_CHUNK_TOKENS,\n",
    "        chunk_overlap=CHUNK_OVERLAP_TOKENS,\n",
    "    )\n",
    "\n",
    "    docs: List[Document] = []\n",
    "    for p in paths:\n",
    "        try:\n",
    "            with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"[Warn] Skipping {p}: {e}\")\n",
    "            continue\n",
    "\n",
    "        base_text = json_to_text(data, file_name=os.path.basename(p))\n",
    "        chunks = splitter.split_text(base_text)\n",
    "\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"source_file\": os.path.basename(p),\n",
    "                    \"chunk_index\": idx,\n",
    "                    \"total_chunks\": len(chunks),\n",
    "                },\n",
    "            )\n",
    "            docs.append(doc)\n",
    "\n",
    "    print(f\"[Info] Prepared {len(docs)} chunk(s) from {len(paths)} file(s).\")\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f8b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INGEST INTO CHROMA\n",
    "\n",
    "\n",
    "def build_or_load_vectorstore(docs: List[Document]) -> Chroma:\n",
    "    \"\"\"\n",
    "    Create or load a persistent Chroma vector store (via LangChain).\n",
    "    Persistence is automatic when 'persist_directory' is set (no .persist()).\n",
    "    \"\"\"\n",
    "    if RESET_COLLECTION and os.path.exists(PERSIST_DIR):\n",
    "        try:\n",
    "            shutil.rmtree(PERSIST_DIR)\n",
    "            print(f\"[Info] Removed existing Chroma store at {PERSIST_DIR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warn] Failed to remove {PERSIST_DIR}: {e}\")\n",
    "\n",
    "    if docs:\n",
    "        vs = Chroma.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            persist_directory=PERSIST_DIR,     # ensures on-disk persistence automatically\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"},  # optional: set metric explicitly\n",
    "        )\n",
    "        print(f\"[Success] Ingested {len(docs)} chunks into '{COLLECTION_NAME}' at {PERSIST_DIR}.\")\n",
    "        return vs\n",
    "\n",
    "    # Load existing store if no new docs are provided.\n",
    "    vs = Chroma(\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        persist_directory=PERSIST_DIR,\n",
    "    )\n",
    "    print(f\"[Info] Loaded existing Chroma store from {PERSIST_DIR}\")\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b4a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE QUERY / RETRIEVAL\n",
    "\n",
    "def run_query(vs: Chroma, query: str, k: int = 4):\n",
    "    \"\"\"\n",
    "    Performs a similarity search using the same Azure embeddings.\n",
    "    Returns documents with metadata + distances (if needed).\n",
    "    \"\"\"\n",
    "    # LangChain Chroma: similarity_search returns top-k Documents\n",
    "    results = vs.similarity_search(query, k=k)\n",
    "\n",
    "    print(\"\\n=== Top Matches ===\")\n",
    "    for i, d in enumerate(results, start=1):\n",
    "        md = d.metadata or {}\n",
    "        src = md.get(\"source_file\", \"unknown\")\n",
    "        idx = md.get(\"chunk_index\", -1)\n",
    "        total = md.get(\"total_chunks\", -1)\n",
    "        print(f\"\\nRank #{i}\")\n",
    "        print(f\"Source: {src} (chunk {idx+1}/{total})\")\n",
    "        preview = d.page_content[:500].replace(\"\\n\", \" \")\n",
    "        if len(d.page_content) > 500:\n",
    "            preview += \" ...\"\n",
    "        print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e782844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Prepared 7 chunk(s) from 4 file(s).\n",
      "[Success] Ingested 7 chunks into 'json_embeddings' at ./database.\n",
      "\n",
      "=== Top Matches ===\n",
      "\n",
      "Rank #1\n",
      "Source: transactions.json (chunk 2/3)\n",
      "[10].name: PRODUCT columns[10].type: TEXT columns[10].description: Type of product. The available types of products are 'Bond', 'Consumer loan', 'Corporate loan', 'Credit Cards', 'Guarantee', 'Investment Loan', 'Letter of Credit', 'Mortgage loan', 'Multipurpose Line', 'Other loan', and 'Overdraft'. These values are usually used in questions that involve type of product. A product may be referred to with or without capitalization and in cases of multi-word description it may be referred to with o ...\n",
      "\n",
      "Rank #2\n",
      "Source: transactions.json (chunk 2/3)\n",
      "[10].name: PRODUCT columns[10].type: TEXT columns[10].description: Type of product. The available types of products are 'Bond', 'Consumer loan', 'Corporate loan', 'Credit Cards', 'Guarantee', 'Investment Loan', 'Letter of Credit', 'Mortgage loan', 'Multipurpose Line', 'Other loan', and 'Overdraft'. These values are usually used in questions that involve type of product. A product may be referred to with or without capitalization and in cases of multi-word description it may be referred to with o ...\n",
      "\n",
      "Rank #3\n",
      "Source: transactions.json (chunk 3/3)\n",
      "_table: collaterals relationships[1].join_type: composite on (REF_DATE, COLL_ID) relationships[1].cardinality: many-to-1 from 'transactions' to 'collaterals' for a given (REF_DATE, COLL_ID) relationships[1].columns[0].local_column: REF_DATE relationships[1].columns[0].foreign_column: REF_DATE relationships[1].columns[0].local_role: part of foreign key relationships[1].columns[0].foregin_role: part of primary key relationships[1].columns[1].local_column: COLL_ID relationships[1].columns[1].foreig ...\n",
      "\n",
      "Rank #4\n",
      "Source: transactions.json (chunk 3/3)\n",
      "_table: collaterals relationships[1].join_type: composite on (REF_DATE, COLL_ID) relationships[1].cardinality: many-to-1 from 'transactions' to 'collaterals' for a given (REF_DATE, COLL_ID) relationships[1].columns[0].local_column: REF_DATE relationships[1].columns[0].foreign_column: REF_DATE relationships[1].columns[0].local_role: part of foreign key relationships[1].columns[0].foregin_role: part of primary key relationships[1].columns[1].local_column: COLL_ID relationships[1].columns[1].foreig ...\n",
      "\n",
      "Rank #5\n",
      "Source: customers.json (chunk 1/2)\n",
      "Source: customers.json table: customers description: Stores information on customer level columns[0].name: REF_DATE columns[0].type: DATE columns[0].description: Reference date (sometimes referred to as 'reporting date'), the last working date of the month in 'DD-MM-YYYY' format. columns[0].nullable: False columns[1].name: PARTNER_ID columns[1].type: TEXT columns[1].description: The indetifier/number of the client. The client is ofter referred to as 'borrower', 'customer' or 'partner'. columns[1 ...\n",
      "\n",
      "Rank #6\n",
      "Source: customers.json (chunk 1/2)\n",
      "Source: customers.json table: customers description: Stores information on customer level columns[0].name: REF_DATE columns[0].type: DATE columns[0].description: Reference date (sometimes referred to as 'reporting date'), the last working date of the month in 'DD-MM-YYYY' format. columns[0].nullable: False columns[1].name: PARTNER_ID columns[1].type: TEXT columns[1].description: The indetifier/number of the client. The client is ofter referred to as 'borrower', 'customer' or 'partner'. columns[1 ...\n",
      "\n",
      "Rank #7\n",
      "Source: customers.json (chunk 2/2)\n",
      " constraints.unique.columns[0]: REF_DATE constraints.unique.columns[1]: PARTNER_ID constraints.unique.description: Combinations of REF_DATE and PARTNER_ID are unique. constraints.non_unique.columns[0]: NACE constraints.non_unique.description: NACE is not unique. relationships[0].related_table: transactions relationships[0].join_type: composite on (REF_DATE, PARTNER_ID) relationships[0].cardinality: 1-to-many from 'customers' to 'transactions' for a given (REF_DATE, PARTNER_ID) relationships[0].c ...\n",
      "\n",
      "Rank #8\n",
      "Source: customers.json (chunk 2/2)\n",
      " constraints.unique.columns[0]: REF_DATE constraints.unique.columns[1]: PARTNER_ID constraints.unique.description: Combinations of REF_DATE and PARTNER_ID are unique. constraints.non_unique.columns[0]: NACE constraints.non_unique.description: NACE is not unique. relationships[0].related_table: transactions relationships[0].join_type: composite on (REF_DATE, PARTNER_ID) relationships[0].cardinality: 1-to-many from 'customers' to 'transactions' for a given (REF_DATE, PARTNER_ID) relationships[0].c ...\n"
     ]
    }
   ],
   "source": [
    "docs = load_json_files(INPUT_DIR)\n",
    "vectorstore = build_or_load_vectorstore(docs)\n",
    "\n",
    "# Sample query (adjust or comment out)\n",
    "run_query(vectorstore, \"Which are the corporate rating models?\", k=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c90414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".agents-ud (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
